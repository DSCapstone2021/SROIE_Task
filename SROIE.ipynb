{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'company': 'ONE ONE THREE SEAFOOD RESTAURANT SDN BHD', 'date': '23-06-2018', 'address': 'NO.1, TAMAN SRI DENGKIL, JALAN AIR HITAM 43800 DENGKIL, SELANGOR.', 'total': '179.50'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# Open a single json\n",
    "directory = '0325updated.task2train(626p)'\n",
    "filename = 'X51008164999.jpg'\n",
    "with open('0325updated.task2train(626p)/X51008164999.txt') as json_file:\n",
    "    data = json.load(json_file)\n",
    "float(data['total'])\n",
    "print(data)\n",
    "\n",
    "# Open a single image and convert it to a tensor\n",
    "image = Image.open(os.path.join(directory,filename))\n",
    "image.show()\n",
    "resized_im = image.resize((1024, 2048))\n",
    "x = TF.to_tensor(resized_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 632\n",
      " Number of txt files: 648 \n",
      "This doesn't quite work... How are there more txt files?\n"
     ]
    }
   ],
   "source": [
    "# Bad code to check how many images and how many txt files there are :p\n",
    "# Without checking for repeated ones: 876 txt and 735 images \n",
    "\n",
    "count_images = 0\n",
    "count_txt = 0\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".jpg\") and not (filename.endswith(\"(1).jpg\") or filename.endswith(\"(2).jpg\" or \\\n",
    "                                    filename.endswith(\"(3).jpg\") or filename.endswith(\"(4).jpg\"))):\n",
    "        count_images += 1\n",
    "    elif filename.endswith(\".txt\") and not (filename.endswith(\"(1).txt\") or filename.endswith(\"(2).txt\" or \\\n",
    "                                    filename.endswith(\"(3).txt\") or filename.endswith(\"(4).txt\")) \\\n",
    "                                           or filename.endswith(\"(5).txt\") or filename.endswith(\"(6).txt\")):\n",
    "        count_txt += 1\n",
    "print(\"Number of images: {}\\n Number of txt files: {} \".format(count_images,count_txt))\n",
    "print(\"This doesn't quite work... How are there more txt files?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X51006619697\n",
      "X51006619697.txt\n"
     ]
    }
   ],
   "source": [
    "# Find jpg and then find corresponding txt\n",
    "image_name_jpg = 'X51005442376.jpg'\n",
    "partitioned_string = filename.partition('.')\n",
    "image_name_ = partitioned_string[0]\n",
    "print(image_name_)\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.startswith(image_name_) and filename.endswith('.txt'):\n",
    "        print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '0325updated.task2train(626p)'\n",
    "\n",
    "# First get the image -> then find the corresponding txt file O(n^2) \n",
    "images = np.empty(736, dtype = torch.Tensor)\n",
    "labels = np.empty(736, dtype=torch.Tensor)\n",
    "counter1 = 0\n",
    "counter2 = 0\n",
    "found_image = False\n",
    "count = 0\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".jpg\") and not found_image:\n",
    "        partitioned_string = filename.partition('.')\n",
    "        image_name = partitioned_string[0]\n",
    "#         print(image_name, type(image_name))\n",
    "#         print(\"Filename1: \", filename)\n",
    "        image = Image.open(os.path.join(directory,filename))\n",
    "        resized_im = image.resize((1024, 2048))\n",
    "        # image.show()\n",
    "        x = torch.flatten(TF.to_tensor(resized_im))\n",
    "        found_image = True\n",
    "        \n",
    "    \n",
    "    go_out = False\n",
    "    if found_image: # Only look for txt file if we already have an image\n",
    "        for filename2 in os.listdir(directory):\n",
    "            if filename2.startswith(image_name) and filename2.endswith(\".txt\"):\n",
    "                with open(os.path.join(directory,filename2)) as json_file:\n",
    "        #                     data = json.load(json_file)\n",
    "                    # print(\"Filename: \", filename, \"Filename2\", filename2, counter1)\n",
    "                    images[counter1] = x\n",
    "                    labels[counter1] = json.load(json_file)['total']\n",
    "                    counter1 += 1\n",
    "    #             found_image = False\n",
    "                    go_out = True\n",
    "                    found_image = False\n",
    "            if go_out:\n",
    "                break\n",
    "        found_image = False # We couldn't find corresponding txt file\n",
    "\n",
    "# 6291456 size of each torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(736,) (736,)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'classify' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-e779a244aca4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mindexes_to_remove\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"float\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'classify' is not defined"
     ]
    }
   ],
   "source": [
    "from re import sub\n",
    "from decimal import Decimal\n",
    "\n",
    "X_train = images.copy() # deep copy?\n",
    "y_train = labels.copy()\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "count_ = 0\n",
    "indexes_to_remove = []\n",
    "for ind, num in enumerate(y_train):\n",
    "    if num == None:\n",
    "        indexes_to_remove.append(ind)\n",
    "    elif classify(num) == \"float\":\n",
    "        y_train[ind] = float(num)\n",
    "    else: \n",
    "        # We will remove it from both x_train and y_train since it is not a float...\n",
    "        indexes_to_remove.append(ind)\n",
    "#         y_train = np.delete(y_train, ind)\n",
    "#         X_train = np.delete(X_train, ind)\n",
    "\n",
    "print(indexes_to_remove)\n",
    "y_train = np.delete(y_train, indexes_to_remove)\n",
    "X_train = np.delete(X_train, indexes_to_remove)\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(726,) (726,)\n",
      "[7.6 12.0 72.0 8.2 36.0 119.7 3.7 8.7 5.9 329.1 25.15 41.87 31.45 35.4\n",
      " 65.2 62.0 9.0 55.1 52.1 14.85 21.5 89.0 2.4 7.4 4.7 22.9 68.41 19.31 39.8\n",
      " 12.72 60.6 98.35 7.3 27.1 12.0 15.9 8.7 31.8 12.0 5.9 23.2 247.55 3.9\n",
      " 52.8 46.06 5.3 7.0 73.55 50.6 593.1 6.0 8.1 28.05 153.35 13.1 63.35 20.4\n",
      " 83.0 21.6 29.3 9.0 14.0 45.0 8.7 16.0 2.0 31.45 32.7 19.4 29.68 40.0 18.0\n",
      " 55.1 73.0 38.0 2.5 6.85 15.4 68.1 5.0 179.5 7.7 165.0 148.0 14.65 7.42\n",
      " 142.0 23.56 18.9 23.25 10.2 53.3 12.4 2.5 6.0 39.0 25.6 5.9 6.0 248.05\n",
      " 21.0 2.1 21.0 8.5 38.37 476.8 25.85 6.6 53.3 12.15 30.1 29.8 16.0 24.0\n",
      " 8.7 39.9 29.3 27.2 758.7 42.4 33.8 42.4 7.7 6.7 7.4 62.8 48.15 73.0 18.9\n",
      " 47.7 5.3 23.6 41.95 112.35 7.5 6.0 60.24 30.9 8.7 50.8 9.3 9.9 3.21 25.45\n",
      " 8.9 10.3 51.42 7.4 7.0 7.7 7.97 102.0 10.3 41.2 9.9 93.07 8.6 46.9 24.0\n",
      " 58.86 31.05 81.8 14.9 11.2 112.45 71.9 21.0 137.15 52.0 7.4 19.0 22.65\n",
      " 51.3 101.75 28.5 71.0 78.1 79.35 9.65 21.2 39.75 116.28 23.0 35.0 12.0\n",
      " 12.6 105.0 39.6 14.65 7.0 53.6 42.5 86.0 4.0 8.2 31.32 18.0 15.0 11.25\n",
      " 12.0 42.35 22.58 6.7 473.3 11.1 14.4 2.12 35.0 5.3 15.0 17.7 56.0 9.0\n",
      " 36.36 277.0 72.93 8.7 60.0 14.9 15.9 99.0 28.2 60.0 35.4 3.9 6.7 234.4\n",
      " 62.6 11.8 8.7 6.36 29.7 75.7 217.0 110.46 29.0 4.2 73.0 9.1 270.3 4.6 8.2\n",
      " 7838.8 73.0 36.55 43.4 20.0 250.0 11.6 62.0 12.72 136.0 12.0 19.9 327.0\n",
      " 4.0 12.37 64.7 113.8 13.6 39.8 68.9 15.9 9.6 65.55 489.3 13.1 79.35 4.5\n",
      " 16.5 21.2 7.0 10.6 190.0 4.8 54.15 5.9 374.2 5.3 8.2 12.8 15.4 3.7 4.6\n",
      " 8.5 8.2 7.8 21.2 4.1 5.0 5.9 48.0 48.95 14.1 8.7 88.95 5.8 14.0 53.55\n",
      " 7.15 21.0 25.4 102.0 17.7 15.0 8.95 6.0 16.3 48.0 45.35 1.5 83.0 20.0\n",
      " 174.9 72.93 27.25 5.0 38.0 41.44 49.4 2.3 8.5 31.8 30.45 41.5 5.0 13.25\n",
      " 15.9 22.58 28.15 8.2 4.6 63.6 12.3 28.6 8.6 31.0 44.9 94.87 30.0 191.2\n",
      " 180.1 7.0 159.0 15.9 6.0 102.0 12.3 27.3 48.1 11.6 5.0 5.0 73.0 18.0 73.0\n",
      " 10.4 27.0 12.0 6.0 20.8 9.0 85.1 59.54 116.28 14.2 7.8 14.2 6.5 130.0\n",
      " 17.22 129.3 37.1 12.3 21.2 538.0 33.6 22.9 30.0 8.7 30.7 141.5 26.1 111.9\n",
      " 18.8 53.2 174.9 404.39 5.0 28.9 361.46 78.3 5.9 47.7 93.0 4.7 9.9 12.3\n",
      " 118.35 3.3 5.0 60.6 20.05 29.68 26.82 9.3 174.9 3.0 332.3 26.8 5.0 35.0\n",
      " 6.7 26.5 4.8 10.45 9.5 39.78 82.68 18.8 4.8 1.38 9.6 12.0 21.2 50.45 1.0\n",
      " 367.1 28.4 3.9 3.2 14.9 7.0 26.1 8.2 68.0 121.9 13.25 83.0 178.08 85.1\n",
      " 50.0 9.0 8.6 189.75 7.0 86.0 15.9 343.95 5.0 85.2 270.0 37.8 22.25 21.4\n",
      " 8.2 104.0 2.5 74.2 8.5 100.0 60.95 2.7 1007.5 1.73 94.87 10.7 25.0 73.0\n",
      " 29.59 15.9 20.5 4.0 4.0 14.79 8.2 52.0 127.2 162.71 190.8 69.2 34.8 20.5\n",
      " 2.1 87.45 43.9 8.2 9.45 51.0 152.0 31.0 8.7 9.9 8.2 99.8 27.55 38.6 275.9\n",
      " 48.04 616.6 6.9 37.45 54.19 8.6 7.1 7.95 7.7 8.4 41.5 101.76 7.0 41.45\n",
      " 27.0 26.1 31.0 14.9 75.0 40.18 60.0 109.7 19.8 34.8 7.0 13.5 8.35 66.0\n",
      " 22.6 156.0 54.5 148.4 67.85 79.5 39.75 63.8 64.15 11.4 77.2 41.45 50.0\n",
      " 8.2 15.4 3.21 25.0 362.5 8.0 38.8 41.0 5.0 1.75 5.8 43.7 7.0 30.0 31.2\n",
      " 39.87 4.5 33.05 24.4 87.45 635.0 17.45 599.45 164.8 39.75 50.8 33.9 9.1\n",
      " 8.7 54.5 14.9 5.8 86.0 15.9 24.0 21.5 40.18 12.0 70.3 7.6 39.9 13.3 8.5\n",
      " 13.8 7.6 57.8 79.5 23.32 34.0 108.5 3.0 10.0 6.4 2.28 88.17 6.0 22.0 35.0\n",
      " 94.0 73.0 102.4 60.3 51.88 5.3 59.54 5.9 85.54 9.75 7.2 4.25 35.8 2.0\n",
      " 20.21 213.0 44.73 72.0 42.9 13.1 8.7 49.4 170.0 9.2 100.6 39.9 8.7 7.1\n",
      " 21.8 99.0 10.6 28.7 3.0 36.0 5.75 4.4 72.75 110.46 28.0 4.8 165.0 50.0\n",
      " 250.0 11.25 50.45 21.85 20.9 9.0 33.9 13.5 110.0 52.4 68.63 11.5 31.6\n",
      " 46.55 24.83 71.0 3.9 28.0 61.65 8.2 127.35 65.5 100.9 21.0 2.56 28.3 10.0\n",
      " 100.0 87.1 82.8 11.4 48.95 465.34 8.0 99.9 7.7 45.0 86.0 4.9 100.0 5.9\n",
      " 33.5 13.78 92.8 34.21 28.5 73.3 65.7 4.8 80.9 102.4 182.0 27.55 4.9 57.4\n",
      " 148.5 30.3 58.0 177.2 19.2 23.4 30.9 31.0 27.9 12.15 59.0 12.5 50.0 148.4\n",
      " 12.72 86.0 39.8 26.6 15.15 33.8 53.14 35.01 7.4 122.8 94.19 28.0 8.2 3.9\n",
      " 8.2 5.8 6.0 96.2]\n"
     ]
    }
   ],
   "source": [
    "from re import sub\n",
    "from decimal import Decimal\n",
    "\n",
    "X_train = images.copy() # deep copy?\n",
    "y_train = labels.copy()\n",
    "\n",
    "for ind, num in enumerate(y_train):\n",
    "    if num == None:\n",
    "        indexes_to_remove.append(ind)\n",
    "    else: \n",
    "        # We will remove it from both x_train and y_train since it is not a float...\n",
    "        # print(num, type(num), len(num))\n",
    "        if len(num) > 0:\n",
    "            y_train[ind] = float(Decimal(sub(r'[^\\d.]', '', num)))\n",
    "        else:\n",
    "            indexes_to_remove.append(ind)\n",
    "                               \n",
    "y_train = np.delete(y_train, indexes_to_remove)\n",
    "X_train = np.delete(X_train, indexes_to_remove)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(y_train)\n",
    "\n",
    "                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_to_remove = []\n",
    "for ind, tensor_ in enumerate(X_train):\n",
    "    if tensor_.size()[0] != 6291456:\n",
    "        ind_to_remove.append(ind)\n",
    "#         print(ind)\n",
    "    \n",
    "# print(\"Finished\")\n",
    "y_train = np.delete(y_train, ind_to_remove)\n",
    "X_train = np.delete(X_train, ind_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n",
      "(723,)\n"
     ]
    }
   ],
   "source": [
    "# print(y_train)\n",
    "# from re import sub\n",
    "# from decimal import Decimal\n",
    "\n",
    "# money = 'RE$6,150,593.22'\n",
    "# value = Decimal(sub(r'[^\\d.]', '', money))\n",
    "# print(value)\n",
    "print(type(int(y_train[0])))\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea: Create a Neural Network that gets the image and ouputs the total\n",
    "\n",
    "class network(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(network, self).__init__()\n",
    "        self.layer1 = torch.nn.Linear(in_features=6291456, out_features=40)\n",
    "        self.layer2 = torch.nn.Linear(in_features=40, out_features=30)\n",
    "        self.layer3 = torch.nn.Linear(in_features = 30, out_features=15)\n",
    "        self.outputlayer = torch.nn.Linear(in_features=15, out_features=1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        x = torch.relu(self.layer2(x))\n",
    "        x = torch.relu(self.layer3(x))\n",
    "        x = self.outputlayer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-6e9161d5cb33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneural_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_train_row\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "EPOCHS = 200\n",
    "batch_size = 8\n",
    "neural_network = network()\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(neural_network.parameters(), lr = learning_rate)\n",
    "\n",
    "loss_in_epoch = []\n",
    "accuracy_in_epoch = []\n",
    "for epoch in range(EPOCHS):\n",
    "    for X_train_row, y_train_row in zip(X_train, y_train):\n",
    "        optimizer.zero_grad()\n",
    "        output = neural_network(X_train_row)\n",
    "        loss = criterion(output, torch.Tensor([y_train_row]))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "#     if (epoch % 10 == 0):\n",
    "#         print()\n",
    "#         loss_in_epoch.append(loss.item())\n",
    "#         pred = torch.argmax(neural_network(torch.tensor(X_train)), dim=1).numpy()\n",
    "#         accuracy_in_epoch.append(np.sum(pred == y_train)/len(y_train))\n",
    "#         print(np.sum(pred == y_train)/len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
